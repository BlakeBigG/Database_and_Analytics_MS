{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction, Transform, and Load\n",
    "\n",
    "ETL is a common necessity for data engineering and data processing pipelines.\n",
    "The source of the data may be other structured databases, unstructured data stores, data APIs, etc.\n",
    "\n",
    "ETL can be a simple data acquisition task, such as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AutomatedDataAcquisition.png MISSING](../images/AutomatedDataAcquisition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Or, it may be part of larger process to accumulated data and information in support of advanced analytical systems.**\n",
    "\n",
    "![AutomatedDataAcquisition_to_Analytics.png MISSING](../images/AutomatedDataAcquisition_to_Analytics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## In the context of ETL, you now have the tools to perform this activity.\n",
    "\n",
    "In the data loading lab, you read in two data files into the Pandas dataframes and prepare the data for loading. You then loaded the database with the data. To design and load a database, we need to understand how to acquire data from a remote resource, such as the web or an API and process it with Pandas.\n",
    "\n",
    "In the loading lab we explored psycopg2 for loading database. In this notebook we will see how to use the SQLAlchemy library to simplify data loading. More specifically, we will extract data from a wikipage, transform the data into pandas dataframe, and then load the database directly from the pandas dataframe. This lab is an example of automating each step of ETL. \n",
    "\n",
    "\n",
    "## Tasks:\n",
    "\n",
    " **Consider**:\n",
    " + https://en.wikipedia.org/wiki/Land_use_statistics_by_country   \n",
    " \n",
    "In the cells below, \n",
    "\n",
    " 1. Define a table for information about the worlds countries.\n",
    " 1. Describe some challenges you foresee with the data\n",
    " 1. Review and modify code cells that pull down the data from the tables into a data frame\n",
    " 1. Load the data into your database\n",
    " 1. Test loaded data with SQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Tables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE SSO.land_use_statistics (\n",
    "    country              varchar(100), -- Character String, varied length\n",
    "    rank                 INT NOT NULL, -- Integer\n",
    "    cultivated_land_k    INT NOT NULL,\n",
    "    cultivated_land_p    REAL NOT NULL, -- Floating point number\n",
    "    arable_land_k        INT NOT NULL,\n",
    "    arable_land_p        REAL NOT NULL,\n",
    "    permanent_crops_k    INT NOT NULL,\n",
    "    permanent_crops_p    REAL NOT NULL,\n",
    "    other_land_k         REAL NOT NULL,\n",
    "    other_land_p         REAL NOT NULL,\n",
    "    total_area           REAL NOT NULL,\n",
    "    date_yr              INT NOT NULL,\n",
    "    CONSTRAINT pk_land_use_statistics\n",
    "     PRIMARY KEY (country)\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using SQLAlchemy for creating a table and loading data into the table. For programmatic access you have two options: psycopg2 and sqlalchemy. The later is more powerful. If you plan to stick to one, then I think sqlalchemy is the right option. \n",
    "\n",
    "Now we will create a query string with the above create statement and execute the query with a sqlalchemy engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "mypasswd = getpass.getpass()\n",
    "username = 'SSO'\n",
    "host = 'pgsql.dsa.lan'\n",
    "database = 'dsa_student'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then connects to the DB\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# SQLAlchemy Connection Parameters\n",
    "postgres_db = {'drivername': 'postgres',\n",
    "               'username': username,\n",
    "               'password': mypasswd,\n",
    "               'host': host,\n",
    "               'database' :database}\n",
    "engine = create_engine(URL(**postgres_db), echo=True)\n",
    "del mypasswd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE IF EXISTS land_use_statistics;\n",
    "CREATE TABLE land_use_statistics (\n",
    "    country              varchar(100), -- Character String, varied length\n",
    "    rank                 INT NOT NULL, -- Integer\n",
    "    cultivated_land_k    INT NOT NULL,\n",
    "    cultivated_land_p    REAL NOT NULL, -- Floating point number\n",
    "    arable_land_k        INT NOT NULL,\n",
    "    arable_land_p        REAL NOT NULL,\n",
    "    permanent_crops_k    INT NOT NULL,\n",
    "    permanent_crops_p    REAL NOT NULL,\n",
    "    other_land_k         REAL NOT NULL,\n",
    "    other_land_p         REAL NOT NULL,\n",
    "    total_area           REAL NOT NULL,\n",
    "    date_yr              INT NOT NULL,\n",
    "    CONSTRAINT pk_land_use_statistics\n",
    "     PRIMARY KEY (country)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    res = connection.execute(query)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Describe the challenges you foresee with the wikipedia data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Add your answer in this cell\n",
    "## ----------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library to query a website\n",
    "import requests\n",
    "# import Beautiful soup library to access functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the url\n",
    "url = \"https://en.wikipedia.org/wiki/Land_use_statistics_by_country\"\n",
    "# Open website URL and return the html to the variable 'response'\n",
    "response = requests.get(url)\n",
    "print(response.encoding)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response we get from web is typically html content. \n",
    "We can read the content of the server's response. \n",
    "Below, when a `BeautifulSoup` object is created from an html response, we explicitly reference the text format(`response.text`).\n",
    "\n",
    "The default encoding format is 'UTF-8' as shown below. \n",
    "\n",
    "[Click here for additional documentations about the response object.](http://docs.python-requests.org/en/master/user/quickstart/#response-content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the html in the 'response' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(response.text, \"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Basic Inspection\n",
    "Use `prettify` function to print the data in its nested html structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract the table which has land usage for each country. This table should be present in one of the html tags.\n",
    "\n",
    "We can work with the tags to extract data present in them.  \n",
    "\"**soup.tag**\": will return the content between opening and closing tag including tag. \n",
    "\n",
    "Additionally, the `.string` value is the data between the tags.\n",
    "Compare the two cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify the html tag**: \n",
    "The data is in a table. \n",
    "You can use inspect element option when you right click the mouse to identify the tag which has the data. \n",
    "\n",
    " * [Additional guide on webpage inspection](../resources/AnalyzingHTMLwithTheWebInspector.pdf)\n",
    "\n",
    "\n",
    "<img src=\"../images/Wikipedia_Inspect_Screen.png\">\n",
    "\n",
    "**If we look at the inspected HTML source for the table,** \n",
    "abbreviated here to focus on the top two rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```HTML\n",
    "<table class=\"sortable wikitable jquery-tablesorter\">\n",
    "\n",
    " <thead>\n",
    "     <tr bgcolor=\"#ececec\" valign=\"top\">\n",
    "         <th data-sort-type=\"number\" class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Rank</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Country</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Cultivated <br> land <br> (km<sup>2</sup>)</th>\n",
    "<th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Cultivated <br> land <br> (%)</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Arable <br> land <br> (km<sup>2</sup>)</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Arable <br> land <br> (%)</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Permanent <br> crops <br> (km<sup>2</sup>)</th>\n",
    "<th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Permanent <br> crops <br> (%)</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Other <br> lands <br> (km<sup>2</sup>)</th>\n",
    "<th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Other <br> lands <br> (%)</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Total <br> area <br> (km<sup>2</sup>)</th>\n",
    "         <th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Date\n",
    "</th>\n",
    "     </tr>\n",
    " </thead>\n",
    " <tbody>\n",
    "<tr>\n",
    "    <td>—</td>\n",
    "    <td><span class=\"flagicon\" style=\"padding-left:25px;\">&nbsp;</span><b><a href=\"/wiki/World\" title=\"World\">World</a></b></td>\n",
    "    <td>17,235,800</td>\n",
    "    <td>11.6</td>\n",
    "    <td>15,749,300</td>\n",
    "    <td>10.6</td>\n",
    "    <td>1,549,600</td>\n",
    "    <td>1</td>\n",
    "    <td>131.701.100</td>\n",
    "    <td>88.4</td>\n",
    "    <td>149,000,000</td>\n",
    "    <td>2011\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>1</td>\n",
    "    <td><span class=\"flagicon\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/23px-Flag_of_India.svg.png\" decoding=\"async\" width=\"23\" height=\"15\" class=\"thumbborder\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/35px-Flag_of_India.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/45px-Flag_of_India.svg.png 2x\" data-file-width=\"1350\" data-file-height=\"900\">&nbsp;</span><a href=\"/wiki/India\" title=\"India\">India</a></td>\n",
    "    <td>1,891,761</td>\n",
    "    <td>57</td>\n",
    "    <td>1,753,694</td>\n",
    "    <td>52.8</td>\n",
    "    <td>138,067</td>\n",
    "    <td>4.2</td>\n",
    "    <td>1,395,502</td>\n",
    "    <td>43</td>\n",
    "    <td>3,287,263</td>\n",
    "    <td>2011\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>2</td>\n",
    "    <td><span class=\"flagicon\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/23px-Flag_of_the_United_States.svg.png\" decoding=\"async\" width=\"23\" height=\"12\" class=\"thumbborder\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/35px-Flag_of_the_United_States.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/46px-Flag_of_the_United_States.svg.png 2x\" data-file-width=\"1235\" data-file-height=\"650\">&nbsp;</span><a href=\"/wiki/United_States\" title=\"United States\">United States</a></td>\n",
    "    <td>1,681,826</td>\n",
    "    <td>17.1</td>\n",
    "    <td>1,652,028</td>\n",
    "    <td>16.8</td>\n",
    "    <td>29,798</td>\n",
    "    <td>0.3</td>\n",
    "    <td>8,151,691</td>\n",
    "    <td>82.9</td>\n",
    "    <td>9,833,517</td>\n",
    "    <td>2011\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "...\n",
    "</tr></tbody><tfoot></tfoot></table>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the table tag has class settings of:\n",
    " * sortable \n",
    " * wikitable \n",
    " * jquery-tablesorter\n",
    " \n",
    "```HTML\n",
    "<table class=\"sortable wikitable jquery-tablesorter\">\n",
    "```\n",
    "\n",
    "We want to focus on the `wikitable`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can fetch all Tables with a find_all() \n",
    "all_tables=soup.find_all('table')\n",
    "# print(type(all_tables))\n",
    "print(f\"Num of avaiable tables = {len(all_tables)}\")\n",
    "\n",
    "# We can find all of the tables with wikitable class \n",
    "wikitables=soup.find_all('table', {'class':\"wikitable\"})\n",
    "print(f\"Num of avaiable wikitables = {len(wikitables)}\")\n",
    "right_table = wikitables[0]\n",
    "# print(type(right_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tag` element is the table.\n",
    "\n",
    "**Examining the HTML Table Header, we have these columns**\n",
    "\n",
    " * Rank\n",
    " * Country\n",
    " * Cultivated Land km^2\n",
    " * Cultivated Land %\n",
    " * Arable Land km^2\n",
    " * Arable Land %\n",
    " * Permanent Crops km^2\n",
    " * Permanent Crops %\n",
    " * Other lands km^2\n",
    " * Other lands %\n",
    " * Total Area\n",
    " * Date\n",
    "\n",
    "Therefore, a simple approach is to iterate through the HTML table rows, the `<tr>...</tr>` and process the data elements.\n",
    "\n",
    "Reviewing the HTML above, we see we need to skip the headers and the \"World\" row.\n",
    "\n",
    "Additionally, we will stop processing when we get out of the ranked rows, that is when Rank is not a number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will use the locale library so we can use \n",
    "# atof and atoi to convert alphanumeric to float and integers, respectively.\n",
    "import locale\n",
    "locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' ) \n",
    "\n",
    "rank=[]\n",
    "country=[]\n",
    "cultivated_land_k=[]\n",
    "cultivated_land_p=[]\n",
    "arable_land_k=[]\n",
    "arable_land_p=[]\n",
    "permanent_crops_k=[]\n",
    "permanent_crops_p=[]\n",
    "other_land_k=[]\n",
    "other_land_p=[]\n",
    "total_area=[]\n",
    "date_yr=[]\n",
    "\n",
    "\n",
    "# skip first iteration as we dont need headers\n",
    "for row in right_table.findAll(\"tr\")[1:]: \n",
    "    # for each row, pull out the td elements.\n",
    "    cells = row.findAll('td') # To store all other details\n",
    "    \n",
    "\n",
    "#     print(f\"cells = {cells}\")    \n",
    "    \n",
    "    this_rank = cells[0].find(text=True)\n",
    "    print(\"Processing rank {}\".format(this_rank))\n",
    "\n",
    "    # If the rank is a number, we can convert it\n",
    "    if (not this_rank.isnumeric()):\n",
    "        print(\"Non-Ranked, skipping\")\n",
    "        continue\n",
    "        \n",
    "    rank.append(locale.atoi(this_rank))\n",
    "\n",
    "    # for the country name, we need to find the name (text) in the Country Hyperlink (a)\n",
    "    countr_cell = cells[1].find('a').find(text=True)\n",
    "    print(countr_cell)\n",
    "\n",
    "    country.append(countr_cell)\n",
    "\n",
    "    # Adjust the the data from Text to numeric data types\n",
    "    cultivated_land_k.append(locale.atoi(cells[2].find(text=True)))\n",
    "    cultivated_land_p.append(locale.atof(cells[3].find(text=True)))\n",
    "\n",
    "    arable_land_k.append(locale.atoi(cells[4].find(text=True)))\n",
    "    arable_land_p.append(locale.atof(cells[5].find(text=True)))\n",
    "\n",
    "    permanent_crops_k.append(locale.atoi(cells[6].find(text=True)))\n",
    "    permanent_crops_p.append(locale.atof(cells[7].find(text=True)))\n",
    "\n",
    "    # Note, that this is to float because the vatican row has a non-int value\n",
    "    other_land_k.append(locale.atof(cells[8].find(text=True)))\n",
    "    other_land_p.append(locale.atof(cells[9].find(text=True)))\n",
    "\n",
    "    total_area.append(locale.atof(cells[10].find(text=True)))\n",
    "    date_yr.append(locale.atoi(cells[11].find(text=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we have built all our columns, stack into a data frame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({'country': country,\n",
    "                'rank': rank,\n",
    "                'cultivated_land_k': cultivated_land_k,\n",
    "                'cultivated_land_p': cultivated_land_p,\n",
    "                'arable_land_k': arable_land_k,\n",
    "                'arable_land_p': arable_land_p,\n",
    "                'permanent_crops_k': permanent_crops_k,\n",
    "                'permanent_crops_p': permanent_crops_p,\n",
    "                'other_land_k': other_land_k,\n",
    "                'other_land_p': other_land_p,\n",
    "                'total_area': total_area,\n",
    "                'date_yr': date_yr\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check our column data types!\n",
    "Does this match the data types we sketched out in the `CREATE TABLE` statement above?\n",
    "If you need to adjust the definition, this would be the time.\n",
    "Alternatively, we can adjust the columns using Pandas techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our Panda data frame and the SQL table inline, we can load it into the database.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load the data into your database\n",
    "\n",
    "This time, instead of the manual loading, we are going to use the SQLAlchemy library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When you run the cell below, carefully examine the output so you see what the SQLAlchemy library is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Now that SQLAlchemy is loaded, the to_sql function\n",
    "df.to_sql('land_use_statistics', # The table to load\n",
    "          engine,             # The engine created above\n",
    "          schema= username,   # The schema where the table lives, our pawprint\n",
    "          if_exists='append', # If the table is found, it would keep loading the end of table.\n",
    "          index=False,        # Ignore creating an index for the index col in the dataframe\n",
    "          chunksize=20)       # Do 20 records from the data frame at a time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that if we had not defined the table `land_use_statistics` in Step 1, the above code would still create a table in the database and load with data from the dataframe.** In this case engine create a table with dataframe columns as attributes. But there is no easy way to define the primary key with this approach. We need to alter the table aftewards to include any primary key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test loaded data with SQL queries\n",
    "\n",
    "\n",
    "```SQL\n",
    "select * from land_use_statistics limit 2;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "If the data was not loaded, please restart from the top and carefully check and redo each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    res = connection.execute(\"select * from land_use_statistics limit 2\")\n",
    "    for row in res:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Now that the data is loaded, let's pull it back out!\n",
    "\n",
    "The following code shows how to load a data into a pandas dataframe without writing a raw query. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backout = pd.read_sql_table(\n",
    "    'land_use_statistics',\n",
    "    con = engine,             # The engine created above\n",
    "    schema= username   # The schema where the table lives, our pawprint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backout.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backout.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
